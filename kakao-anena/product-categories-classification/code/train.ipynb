{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "immediate-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import easydict\n",
    "import cate_dataset\n",
    "import cate_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compound-republican",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')\n",
    "DB_PATH = f'../input/processed'\n",
    "VOCAB_DIR = os.path.join(DB_PATH, 'vocab')\n",
    "MODEL_PATH = f'../model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "returning-shade",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    learning_rate = 3.0e-4  # 러닝 레이트\n",
    "    batch_size = 1024  # 배치 사이즈\n",
    "    num_workers = 4  # 워커의 개수\n",
    "    print_freq = 100  # 결과 출력 빈도\n",
    "    start_epoch = 0  # 시작 에폭\n",
    "    num_train_epochs = 10  # 학습할 에폭수\n",
    "    warmup_steps = 100  # lr을 서서히 증가시킬 step 수\n",
    "    max_grad_norm = 10  # 그래디언트 클리핑에 사용\n",
    "    weight_decay = 0.01\n",
    "    dropout = 0.2  # dropout 확률\n",
    "    seed = 7\n",
    "    hidden_size = 512  # 은닉 크기\n",
    "    intermediate_size = 256  # TRANSFORMER셀의 intermediate 크기\n",
    "    nlayers = 2  # BERT의 층수\n",
    "    nheads = 8  # BERT의 head 개수\n",
    "    seq_len = 64  # 토큰의 최대 길이\n",
    "    n_b_cls = 57 + 1  # 대카테고리 개수\n",
    "    n_m_cls = 552 + 1  # 중카테고리 개수\n",
    "    n_s_cls = 3190 + 1  # 소카테고리 개수\n",
    "    n_d_cls = 404 + 1  # 세카테고리 개수\n",
    "    vocab_size = 32000  # 토큰의 유니크 인덱스 개수\n",
    "    img_feat_size = 2048  # 이미지 피처 벡터의 크기\n",
    "    type_vocab_size = 30  # 타입의 유니크 인덱스 개수\n",
    "    csv_path = os.path.join(DB_PATH, 'train.csv')\n",
    "    h5_path = os.path.join(DB_PATH, 'train_img_feat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blind-river",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arranged-alloy",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"seed\": 7, \n",
    "    \"fold\": 0, \n",
    "    \"stratified\": True\n",
    "})\n",
    "\n",
    "CFG.seed =  args.seed        \n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(CFG.seed)\n",
    "random.seed(CFG.seed)\n",
    "np.random.seed(CFG.seed)\n",
    "torch.manual_seed(CFG.seed)    \n",
    "torch.cuda.manual_seed(CFG.seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informal-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, epoch, scheduler):\n",
    "    \"\"\"    \n",
    "    한 에폭 단위로 학습을 시킵니다.\n",
    "    매개변수\n",
    "    train_loader: 학습 데이터셋에서 배치(미니배치) 불러옵니다.\n",
    "    model: 학습될 파라미터를 가진 딥러닝 모델\n",
    "    optimizer: 파라미터를 업데이트 시키는 역할\n",
    "    scheduler: learning_rate를 감소시키는 역할\n",
    "    \"\"\"\n",
    "    # AverageMeter는 지금까지 입력 받은 전체 수의 평균 값 반환 용도\n",
    "    batch_time = AverageMeter()     # 한 배치처리 시간 집계\n",
    "    data_time = AverageMeter()      # 데이터 로딩 시간 집계\n",
    "    losses = AverageMeter()         # 손실 값 집계\n",
    "    o_accuracies = AverageMeter()   # 대회 평가 방법으로 집계\n",
    "    b_accuracies = AverageMeter()   # 대카테고리 정확도 집계\n",
    "    m_accuracies = AverageMeter()   # 중카테고리 정확도 집계\n",
    "    s_accuracies = AverageMeter()   # 소카테고리 정확도 집계\n",
    "    d_accuracies = AverageMeter()   # 세카테고리 정확도 집계\n",
    "    \n",
    "    sent_count = AverageMeter()     # 문장 처리 개수 집계\n",
    "    \n",
    "    # 학습 모드로 교체\n",
    "    model.train()\n",
    "\n",
    "    start = end = time.time()\n",
    "    \n",
    "    # train_loader에서 반복해서 학습용 배치 데이터를 받아옵니다.\n",
    "    # CateDataset의 __getitem__() 함수의 반환 값과 동일한 변수 반환\n",
    "    for step, (token_ids, token_mask, token_types, img_feat, label) in enumerate(train_loader):\n",
    "        # 데이터 로딩 시간 기록\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        # 배치 데이터의 위치를 CPU메모리에서 GPU메모리로 이동\n",
    "        token_ids, token_mask, token_types, img_feat, label = (token_ids.cuda(), token_mask.cuda(), token_types.cuda(), img_feat.cuda(), label.cuda())\n",
    "        batch_size = token_ids.size(0)   \n",
    "                \n",
    "        # model은 배치 데이터를 입력 받아서 예측 결과 및 loss 반환\n",
    "        # model은 인스턴스이나 __call__함수가 추가돼 함수처럼 호출이 가능합니다. \n",
    "        # CateClassifier의 __call__ 함수 내에서 forward 함수가 호출됩니다. \n",
    "        loss, pred = model(token_ids, token_mask, token_types, img_feat, label)\n",
    "        loss = loss.mean() # Multi-GPU 학습의 경우 mean() 호출 필요\n",
    "                \n",
    "        # loss 값을 기록\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        \n",
    "        # 역전파 수행\n",
    "        loss.backward()\n",
    "\n",
    "        # CFG.max_grad_norm 이상의 값을 가지는 그래디언트 값 클리핑\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "              \n",
    "        scheduler.step()    # 스케쥴러로 learning_rate 조절\n",
    "        optimizer.step()    # 옵티마이저로 파라미터 업데이터\n",
    "        optimizer.zero_grad() # 옵티마이저 내의 그래디언트 초기화\n",
    "\n",
    "        # 소요시간 측정\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        sent_count.update(batch_size)\n",
    "\n",
    "        # CFG.print_freq 주기대로 결과 로그를 출력\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            # 대/중/소/세가 예측된 pred와 정답 label로 정확도 계산 및 집계\n",
    "            o_acc, b_acc, m_acc, s_acc, d_acc = calc_cate_acc(pred, label)\n",
    "            o_accuracies.update(o_acc, batch_size)\n",
    "            b_accuracies.update(b_acc, batch_size)\n",
    "            m_accuracies.update(m_acc, batch_size)\n",
    "            s_accuracies.update(s_acc, batch_size)\n",
    "            d_accuracies.update(d_acc, batch_size)\n",
    "            \n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.3f}({loss.avg:.3f}) '\n",
    "                  'OAcc: {o_acc.val:.3f}({o_acc.avg:.3f}) '\n",
    "                  'BAcc: {b_acc.val:.3f}({b_acc.avg:.3f}) '\n",
    "                  'MAcc: {m_acc.val:.4f}({m_acc.avg:.3f}) '\n",
    "                  'SAcc: {s_acc.val:.3f}({s_acc.avg:.3f}) '\n",
    "                  'DAcc: {d_acc.val:.3f}({d_acc.avg:.3f}) '                  \n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  'sent/s {sent_s:.0f} '\n",
    "                  .format(\n",
    "                   epoch, step+1, len(train_loader),\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   o_acc=o_accuracies, b_acc=b_accuracies, m_acc=m_accuracies,\n",
    "                   s_acc=s_accuracies, d_acc=d_accuracies,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   grad_norm=grad_norm,\n",
    "                   lr=scheduler.get_lr()[0],                   \n",
    "                   sent_s=sent_count.avg/batch_time.avg\n",
    "                   ))\n",
    "    # 학습 동안 집계된 결과 반환\n",
    "    return (losses.avg, o_accuracies.avg, b_accuracies.avg, m_accuracies.avg, s_accuracies.avg, d_accuracies.avg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "artificial-asset",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def validate(valid_loader, model):\n",
    "    \"\"\"    \n",
    "    한 에폭 단위로 검증합니다.\n",
    "    매개변수\n",
    "    valid_loader: 검증 데이터셋에서 배치(미니배치) 불러옵니다.\n",
    "    model: train 함수에서 학습된 딥러닝 모델\n",
    "    \"\"\"    \n",
    "    batch_time = AverageMeter()     # 한 배치처리 시간 집계\n",
    "    data_time = AverageMeter()      # 데이터 로딩 시간 집계\n",
    "    losses = AverageMeter()         # 손실 값 집계\n",
    "    o_accuracies = AverageMeter()   # 대회 평가 방법으로 집계\n",
    "    b_accuracies = AverageMeter()   # 대카테고리 정확도 집계\n",
    "    m_accuracies = AverageMeter()   # 중카테고리 정확도 집계\n",
    "    s_accuracies = AverageMeter()   # 소카테고리 정확도 집계\n",
    "    d_accuracies = AverageMeter()   # 세카테고리 정확도 집계\n",
    "    \n",
    "    sent_count = AverageMeter()     # 문장 처리 개수 집계\n",
    "    \n",
    "    # 평가(evaluation) 모드로 교체\n",
    "    # 드롭아웃이나 배치정규화가 일관된 값을 내도록 함\n",
    "    model.eval()\n",
    "\n",
    "    start = end = time.time()\n",
    "        \n",
    "    for step, (token_ids, token_mask, token_types, img_feat, label) in enumerate(valid_loader):\n",
    "        # 데이터 로딩 시간 기록\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        # 배치 데이터의 위치를 CPU메모리에서 GPU메모리로 이동\n",
    "        token_ids, token_mask, token_types, img_feat, label = (\n",
    "            token_ids.cuda(), token_mask.cuda(), token_types.cuda(), \n",
    "            img_feat.cuda(), label.cuda())\n",
    "        \n",
    "        batch_size = token_ids.size(0)\n",
    "        \n",
    "        # with문 내에서는 그래디언트 계산을 하지 않도록 함\n",
    "        with torch.no_grad():\n",
    "            # model은 배치 데이터를 입력 받아서 예측 결과 및 loss 반환\n",
    "            loss, pred = model(token_ids, token_mask, token_types, img_feat, label)\n",
    "            loss = loss.mean()\n",
    "                \n",
    "        # loss 값을 기록\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        \n",
    "        # 소요시간 측정\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        sent_count.update(batch_size)\n",
    "\n",
    "        # CFG.print_freq 주기대로 결과 로그를 출력\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            o_acc, b_acc, m_acc, s_acc, d_acc = calc_cate_acc(pred, label)\n",
    "            o_accuracies.update(o_acc, batch_size)\n",
    "            b_accuracies.update(b_acc, batch_size)\n",
    "            m_accuracies.update(m_acc, batch_size)\n",
    "            s_accuracies.update(s_acc, batch_size)\n",
    "            d_accuracies.update(d_acc, batch_size)\n",
    "            \n",
    "            print('TEST: {0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'OAcc: {o_acc.val:.3f}({o_acc.avg:.3f}) '\n",
    "                  'BAcc: {b_acc.val:.3f}({b_acc.avg:.3f}) '\n",
    "                  'MAcc: {m_acc.val:.4f}({m_acc.avg:.3f}) '\n",
    "                  'SAcc: {s_acc.val:.3f}({s_acc.avg:.3f}) '\n",
    "                  'DAcc: {d_acc.val:.3f}({d_acc.avg:.3f}) '\n",
    "                  'sent/s {sent_s:.0f} '\n",
    "                  .format(\n",
    "                   step+1, len(valid_loader),\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   o_acc=o_accuracies, b_acc=b_accuracies, m_acc=m_accuracies,\n",
    "                   s_acc=s_accuracies, d_acc=d_accuracies,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   sent_s=sent_count.avg/batch_time.avg\n",
    "                   ))\n",
    "    # 검증 동안 집계된 결과 반환\n",
    "    return (losses.avg, o_accuracies.avg, b_accuracies.avg, m_accuracies.avg, \n",
    "            s_accuracies.avg, d_accuracies.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "considerable-aspect",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_cate_acc(pred, label):\n",
    "    \"\"\"\n",
    "    대/중/소/세 카테고리별 정확도와 전체(overall) 정확도를 반환\n",
    "    전체 정확도는 대회 평가 방법과 동일한 가중치로 계산\n",
    "    \"\"\"\n",
    "    b_pred, m_pred, s_pred, d_pred= pred    \n",
    "    _, b_idx = b_pred.max(1)\n",
    "    _, m_idx = m_pred.max(1)\n",
    "    _, s_idx = s_pred.max(1)\n",
    "    _, d_idx = d_pred.max(1)\n",
    "        \n",
    "    b_acc = (b_idx == label[:, 0]).sum().item() / (label[:, 0]>0).sum().item()\n",
    "    m_acc = (m_idx == label[:, 1]).sum().item() / (label[:, 1]>0).sum().item()\n",
    "            \n",
    "    s_acc = (s_idx == label[:, 2]).sum().item() / ((label[:, 2]>0).sum().item()+1e-06)\n",
    "    d_acc = (d_idx == label[:, 3]).sum().item() / ((label[:, 3]>0).sum().item()+1e-06)    \n",
    "    o_acc = (b_acc + 1.2*m_acc + 1.3*s_acc + 1.4*d_acc)/4\n",
    "    return o_acc, b_acc, m_acc, s_acc, d_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-midnight",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, model_path, model_filename, is_best=False):\n",
    "    print('saving cust_model ...')\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    torch.save(state, os.path.join(model_path, model_filename))\n",
    "    if is_best:\n",
    "        torch.save(state, os.path.join(model_path, 'best_' + model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "existing-findings",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proved-relaxation",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "choice-premises",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...\n"
     ]
    }
   ],
   "source": [
    "print('loading ...')\n",
    "train_df = pd.read_csv(CFG.csv_path, dtype={'tokens':str})    \n",
    "train_df['img_idx'] = train_df.index # 몇 번째 행인지 img_idx 칼럼에 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compressed-lender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use StratifiedKFold ...\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold 사용\n",
    "if args.stratified:\n",
    "    print('use StratifiedKFold ...')\n",
    "    # 대/중/소/세 카테고리를 결합하여 유니크 카테고리를 만듭니다.\n",
    "    train_df['unique_cateid'] = (train_df['bcateid'].astype('str') + train_df['mcateid'].astype('str') + train_df['scateid'].astype('str') + train_df['dcateid'].astype('str')).astype('category')\n",
    "    train_df['unique_cateid'] = train_df['unique_cateid'].cat.codes\n",
    "\n",
    "    # StratifiedKFold을 사용해 데이터셋을 학습셋(train_df)과 검증셋(valid_df)으로 나눕니다.\n",
    "    folds = StratifiedKFold(n_splits=5, random_state=CFG.seed, shuffle=True)\n",
    "    train_idx, valid_idx = list(folds.split(train_df.values, train_df['unique_cateid']))[args.fold]\n",
    "else:\n",
    "    # KFold을 사용해 데이터셋을 학습셋(train_df)과 검증셋(valid_df)으로 나눕니다.\n",
    "    folds = KFold(n_splits=5, random_state=CFG.seed, shuffle=True)\n",
    "    train_idx, valid_idx = list(folds.split(train_df.values))[args.fold]\n",
    "\n",
    "valid_df = train_df.iloc[valid_idx]\n",
    "train_df = train_df.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ancient-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ... done\n"
     ]
    }
   ],
   "source": [
    "# 토큰을 대응되는 인덱스로 치환할 때 사용될 딕셔너리를 로딩합니다.\n",
    "vocab = [line.split('\\t')[0] for line in open(os.path.join(VOCAB_DIR, 'spm.vocab'), encoding='utf-8').readlines()]\n",
    "token2id = dict([(w, i) for i, w in enumerate(vocab)])\n",
    "print('loading ... done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conservative-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 적합한 형태의 샘플을 가져오는 CateDataset의 인스턴스를 만듭니다.\n",
    "train_db = cate_dataset.CateDataset(train_df, CFG.h5_path, token2id, CFG.seq_len, CFG.type_vocab_size)\n",
    "valid_db = cate_dataset.CateDataset(valid_df, CFG.h5_path, token2id, CFG.seq_len, CFG.type_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "auburn-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_db, batch_size=CFG.batch_size, shuffle=True, drop_last=True, num_workers=CFG.num_workers, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_db, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fallen-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 분류기 모델을 생성합니다.\n",
    "model = cate_model.CateClassifier(CFG)\n",
    "# 모델의 파라미터를 GPU메모리로 옮깁니다.\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bronze-style",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters:  24637551\n"
     ]
    }
   ],
   "source": [
    "# 모델의 파라미터 수를 출력합니다.\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('parameters: ', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "remarkable-cylinder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_optimization_steps 63550\n"
     ]
    }
   ],
   "source": [
    "# 학습 동안 수행될 총 스텝 수\n",
    "# 데이터셋을 배치크기로 나눈 것이 1에폭 동안 스텝 수\n",
    "# 총 스텝 수 = 1에폭 스텝 수 * 총 에폭 수\n",
    "num_train_optimization_steps = int(len(train_db) / CFG.batch_size) * (CFG.num_train_epochs)\n",
    "print('num_train_optimization_steps', num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "later-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 그룹핑 정보 생성\n",
    "# 가중치 감쇠(weight decay) 미적용 파라미터 그룹과 적용 파라미터로 나눔\n",
    "param_optimizer = list(model.named_parameters())    \n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "higher-entry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use WarmupLinearSchedule ...\n",
      "initial learning rate:0.0\n"
     ]
    }
   ],
   "source": [
    "# AdamW 옵티마이저 생성\n",
    "optimizer = AdamW(optimizer_grouped_parameters,lr=CFG.learning_rate,weight_decay=CFG.weight_decay)\n",
    "\n",
    "# learning_rate가 선형적으로 감소하는 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=CFG.warmup_steps,num_training_steps=num_train_optimization_steps)\n",
    "print('use WarmupLinearSchedule ...')\n",
    "\n",
    "def get_lr():    \n",
    "    return scheduler.get_lr()[0]\n",
    "\n",
    "log_df = pd.DataFrame() # 에폭 별 실험결과 로그를 저장할 데이터 프레임\n",
    "curr_lr = get_lr()    \n",
    "print(f'initial learning rate:{curr_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minus-telephone",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4b7345c5dfd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 학습을 진행하고 loss나 accuracy와 같은 결과를 반환합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 검증을 진행하고 loss나 accuracy와 같은 결과를 반환합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalid_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6df597b061fc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, epoch, scheduler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# 배치 데이터의 위치를 CPU메모리에서 GPU메모리로 이동\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         token_ids, token_mask, token_types, img_feat, label = (\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             img_feat.cuda(), label.cuda())\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/enjoy-data-science/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m             raise RuntimeError(\n\u001b[1;32m    185\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m/opt/anaconda3/envs/enjoy-data-science/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# (num_train_epochs - start_epoch) 횟수 만큼 학습을 진행합니다.\n",
    "for epoch in range(CFG.start_epoch, CFG.num_train_epochs):\n",
    "\n",
    "    # 한 에폭의 결과가 집계된 한 행을 반환합니다.\n",
    "    def get_log_row_df(epoch, lr, train_res, valid_res):\n",
    "        log_row = {'EPOCH':epoch, 'LR':lr,\n",
    "                   'TRAIN_LOSS':train_res[0], 'TRAIN_OACC':train_res[1],\n",
    "                   'TRAIN_BACC':train_res[2], 'TRAIN_MACC':train_res[3],\n",
    "                   'TRAIN_SACC':train_res[4], 'TRAIN_DACC':train_res[5],\n",
    "                   'VALID_LOSS':valid_res[0], 'VALID_OACC':valid_res[1],\n",
    "                   'VALID_BACC':valid_res[2], 'VALID_MACC':valid_res[3],\n",
    "                   'VALID_SACC':valid_res[4], 'VALID_DACC':valid_res[5],\n",
    "                   }\n",
    "        return pd.DataFrame(log_row, index=[0])             \n",
    "\n",
    "    # 학습을 진행하고 loss나 accuracy와 같은 결과를 반환합니다.\n",
    "    train_res = train(train_loader, model, optimizer, epoch, scheduler)\n",
    "    # 검증을 진행하고 loss나 accuracy와 같은 결과를 반환합니다.\n",
    "    valid_res = validate(valid_loader, model)\n",
    "    curr_lr = get_lr()\n",
    "    print(f'set the learning_rate: {curr_lr}')\n",
    "\n",
    "    log_row_df = get_log_row_df(epoch, curr_lr, train_res, valid_res)\n",
    "    # log_df에 결과가 집계된 한 행을 추가합니다.\n",
    "    log_df = log_df.append(log_row_df, sort=False)\n",
    "    print(log_df.tail(10)) # log_df의 최신 10개 행만 출력합니다.\n",
    "\n",
    "    # 모델의 파라미터가 저장될 파일의 이름을 정합니다.\n",
    "    curr_model_name = (f'b{CFG.batch_size}_h{CFG.hidden_size}_' f'd{CFG.dropout}_l{CFG.nlayers}_hd{CFG.nheads}_' f'ep{epoch}_s{CFG.seed}_fold{args.fold}.pt')\n",
    "    # torch.nn.DataParallel로 감싸진 경우 원래의 model을 가져옵니다.\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model  \n",
    "\n",
    "print('training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 파라미터를 저장합니다.\n",
    "save_checkpoint({'epoch': epoch + 1,'arch': 'transformer','state_dict': model_to_save.state_dict(),'log': log_df,},MODEL_PATH, curr_model_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-journalist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Enjoy Data Science",
   "language": "python",
   "name": "enjoy-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
